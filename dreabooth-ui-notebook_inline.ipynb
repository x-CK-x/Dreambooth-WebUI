{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Load repo (if needed)\n",
    "!git clone https://github.com/x-CK-x/Dreambooth-WebUI\n",
    "%cd Dreambooth-WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeTrc2vOeiNh",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title BUILD ENV\n",
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title RUN the GUI\n",
    "!python webui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "import subprocess as sub\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "\n",
    "# set local path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# get list of all .ckpt files in directory & set model option buttons\n",
    "ckpt_files = glob.glob(os.path.join(cwd, '*.ckpt'))\n",
    "ckpt_files = [f.split('/')[-1] for f in ckpt_files]\n",
    "\n",
    "# create save file for everything to be written to (open/overwrite/close) whenever changes are saved\n",
    "model_config_df = {}\n",
    "dataset_config_df = {}\n",
    "image_gen_config_df = {}\n",
    "train_config_df = {}\n",
    "system_config_df = {}\n",
    "\n",
    "json_file_name = \"gui_params.json\"\n",
    "file_exists = os.path.exists(json_file_name)\n",
    "if not file_exists:\n",
    "    with open(json_file_name, 'w') as f:\n",
    "        f.close()\n",
    "else:\n",
    "    with open(json_file_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "        model_config_df = [dictionary for dictionary in data if \"model_name\" in dictionary]\n",
    "        if len(model_config_df) > 0:\n",
    "            model_config_df = model_config_df[0]\n",
    "        else:\n",
    "            model_config_df = {}\n",
    "        dataset_config_df = [dictionary for dictionary in data if \"config_path\" in dictionary]\n",
    "        if len(dataset_config_df) > 0:\n",
    "            dataset_config_df = dataset_config_df[0]\n",
    "        else:\n",
    "            dataset_config_df = {}\n",
    "        system_config_df = [dictionary for dictionary in data if \"gpu_used_var\" in dictionary]\n",
    "        if len(system_config_df) > 0:\n",
    "            system_config_df = system_config_df[0]\n",
    "        else:\n",
    "            system_config_df = {}\n",
    "        image_gen_config_df = [dictionary for dictionary in data if \"ddim_eta_var\" in dictionary]\n",
    "        if len(image_gen_config_df) > 0:\n",
    "            image_gen_config_df = image_gen_config_df[0]\n",
    "        else:\n",
    "            image_gen_config_df = {}\n",
    "        train_config_df = [dictionary for dictionary in data if \"max_training_steps\" in dictionary]\n",
    "        if len(train_config_df) > 0:\n",
    "            train_config_df = train_config_df[0]\n",
    "        else:\n",
    "            train_config_df = {}\n",
    "        del data\n",
    "        json_file.close()\n",
    "\n",
    "def verbose_print(text):\n",
    "    if \"verbose\" in model_config_df and model_config_df[\"verbose\"]:\n",
    "        print(f\"{text}\")\n",
    "\n",
    "def execute(cmd):\n",
    "    popen = sub.Popen(cmd, stdout=sub.PIPE, universal_newlines=True)\n",
    "    for stdout_line in iter(popen.stdout.readline, \"\"):\n",
    "        yield stdout_line\n",
    "    popen.stdout.close()\n",
    "    return_code = popen.wait()\n",
    "    if return_code:\n",
    "        raise sub.CalledProcessError(return_code, cmd)\n",
    "\n",
    "def dependency_install_button():\n",
    "    return sub.run(f\"pip install -r {cwd}/requirements.txt\".split(\" \"), stdout=sub.PIPE).stdout.decode(\"utf-8\")\n",
    "\n",
    "def update_JSON():\n",
    "    temp = [model_config_df, dataset_config_df, system_config_df, image_gen_config_df, train_config_df]\n",
    "    for entry in temp:\n",
    "        verbose_print(entry)\n",
    "\n",
    "    with open(json_file_name, \"w\") as f:\n",
    "        json.dump([model_config_df, dataset_config_df, system_config_df, image_gen_config_df, train_config_df], indent=4, fp=f)\n",
    "    f.close()\n",
    "\n",
    "def create_data_dirs():\n",
    "    dataset_type = [\"dataset_path\", \"reg_dataset_path\"]\n",
    "    for i in range(0, len(dataset_type)):\n",
    "        if not os.path.exists(dataset_config_df[dataset_type[i]]) and not dataset_config_df[dataset_type[i]] == '':\n",
    "            dataset = dataset_config_df[dataset_type[i]]\n",
    "            dir_create_str = f\"mkdir -p {dataset}\"\n",
    "            sub.run(dir_create_str.split(\" \"))\n",
    "\n",
    "def model_choice(ver):\n",
    "    for i in range(0, len(ckpt_files)):\n",
    "        if ver == ckpt_files[i]:\n",
    "            return ver\n",
    "    return None\n",
    "\n",
    "def verbose_checkbox():\n",
    "    model_config_df[\"verbose\"] = not model_config_df[\"verbose\"]\n",
    "\n",
    "def model_config_save_button(model_name, gpu_used_var, project_name, class_token, config_path, dataset_path, reg_dataset_path):\n",
    "    model_config_df[\"model_name\"] = model_name\n",
    "    system_config_df[\"gpu_used_var\"] = int(gpu_used_var.replace(\"gpu: \", \"\"))\n",
    "    dataset_config_df[\"project_name\"] = project_name\n",
    "    dataset_config_df[\"class_token\"] = class_token\n",
    "    dataset_config_df[\"config_path\"] = config_path\n",
    "    dataset_config_df[\"dataset_path\"] = dataset_path\n",
    "    dataset_config_df[\"reg_dataset_path\"] = reg_dataset_path\n",
    "\n",
    "    image_gen_config_df[\"final_img_path\"] = dataset_config_df[\"reg_dataset_path\"]\n",
    "\n",
    "    all_lines = None\n",
    "    is_target_same = False\n",
    "    if not dataset_config_df[\"class_token\"] == '':\n",
    "        with open(os.path.join(cwd, \"ldm/data/personalized.py\"), \"r\") as script_file:\n",
    "            lines = script_file.readlines()\n",
    "            for i in range(0, len(lines)):\n",
    "                if \"{}\" in lines[i]:\n",
    "                    prior_class = (lines[i].split(\"\\'\")[1]).split(\" \")[0]\n",
    "                    if prior_class == dataset_config_df[\"class_token\"]:\n",
    "                        is_target_same = True\n",
    "                        break\n",
    "                    lines[i] = lines[i].replace(prior_class, str(dataset_config_df[\"class_token\"]))\n",
    "                    all_lines = lines\n",
    "                    break\n",
    "            script_file.close()\n",
    "        if not is_target_same:\n",
    "            with open(os.path.join(cwd, \"ldm/data/personalized.py\"), \"w\") as script_file:\n",
    "                for line in all_lines:\n",
    "                    script_file.write(line)\n",
    "                script_file.close()\n",
    "\n",
    "    # update json file\n",
    "    update_JSON()\n",
    "\n",
    "    # create directories if necessary\n",
    "    create_data_dirs()\n",
    "\n",
    "    return reg_dataset_path\n",
    "\n",
    "def change_regularizer_view(choice):\n",
    "    if \"Custom\" in choice:\n",
    "        image_gen_config_df[\"regularizer_var\"] = 0\n",
    "    elif \"Auto\" in choice:\n",
    "        image_gen_config_df[\"regularizer_var\"] = 1\n",
    "\n",
    "def image_gen_config_save_button(final_img_path, seed_var, ddim_eta_var, scale_var, prompt_string, n_samples, n_iter, ddim_steps, keep_jpgs):\n",
    "    image_gen_config_df[\"final_img_path\"] = final_img_path\n",
    "    image_gen_config_df[\"seed_var\"] = int(seed_var)\n",
    "    image_gen_config_df[\"ddim_eta_var\"] = float(ddim_eta_var)\n",
    "    image_gen_config_df[\"scale_var\"] = float(scale_var)\n",
    "    image_gen_config_df[\"prompt_string\"] = prompt_string\n",
    "    image_gen_config_df[\"n_samples\"] = int(n_samples)\n",
    "    image_gen_config_df[\"n_iter\"] = int(n_iter)\n",
    "    image_gen_config_df[\"ddim_steps\"] = int(ddim_steps)\n",
    "    image_gen_config_df[\"keep_jpgs\"] = bool(keep_jpgs)\n",
    "\n",
    "    dataset_config_df[\"reg_dataset_path\"] = image_gen_config_df[\"final_img_path\"]\n",
    "\n",
    "    # update json file\n",
    "    update_JSON()\n",
    "\n",
    "    # create directories if necessary\n",
    "    create_data_dirs()\n",
    "\n",
    "    return final_img_path\n",
    "\n",
    "def image_generation_button(keep_jpgs):\n",
    "    prompt = image_gen_config_df['prompt_string'].replace('_', ' ')\n",
    "    image_gen_cmd = f\"python scripts/stable_txt2img.py --seed {image_gen_config_df['seed_var']} \" \\\n",
    "                    f\"--ddim_eta {image_gen_config_df['ddim_eta_var']} --n_samples {image_gen_config_df['n_samples']} \" \\\n",
    "                    f\"--n_iter {image_gen_config_df['n_iter']} --scale {image_gen_config_df['scale_var']} \" \\\n",
    "                    f\"--ddim_steps {image_gen_config_df['ddim_steps']} --ckpt {model_config_df['model_name']} \" \\\n",
    "                    f\"--prompt \\'{prompt}\\' --outdir {image_gen_config_df['final_img_path']}\"\n",
    "\n",
    "    if keep_jpgs:\n",
    "        image_gen_cmd += \" --keep_jpgs\"\n",
    "\n",
    "    verbose_print(\"============================== IMAGE GENERATION TEST ==============================\")\n",
    "    verbose_print(image_gen_cmd)\n",
    "    verbose_print(\"============================== --------------------- ==============================\")\n",
    "\n",
    "    if (\"regularizer_var\" in image_gen_config_df and image_gen_config_df[\"regularizer_var\"] == 1):\n",
    "        if \"seed_var\" in image_gen_config_df and \"ddim_eta_var\" in image_gen_config_df and \\\n",
    "                \"n_samples\" in image_gen_config_df and \"n_iter\" in image_gen_config_df and \\\n",
    "                \"scale_var\" in image_gen_config_df and \"ddim_steps\" in image_gen_config_df and \\\n",
    "                \"model_name\" in model_config_df and \"prompt_string\" in image_gen_config_df and \"final_img_path\" in image_gen_config_df:\n",
    "            for line in execute(image_gen_cmd.split(\" \")):\n",
    "                verbose_print(line)\n",
    "    else:\n",
    "        verbose_print(\"Auto Regularization Method NOT Selected. Please Select the Correct Option to Generate (Regularization Images)\\n\" \\\n",
    "               \"Please make sure to SAVE your settings before trying to Generate and/or Train.\")\n",
    "\n",
    "def train_save_button(max_training_steps, batch_size, cpu_workers):\n",
    "    train_config_df['max_training_steps'] = int(max_training_steps)\n",
    "    train_config_df['batch_size'] = int(batch_size)\n",
    "    train_config_df['cpu_workers'] = int(cpu_workers)\n",
    "\n",
    "    # update json file\n",
    "    update_JSON()\n",
    "\n",
    "    # create directories if necessary\n",
    "    create_data_dirs()\n",
    "\n",
    "def prune_ckpt():\n",
    "    temp_path = os.path.join(cwd, 'logs')\n",
    "    paths = sorted(Path(temp_path).iterdir(), key=os.path.getmtime)\n",
    "    verbose_print(paths)\n",
    "    temp_path = os.path.join(temp_path, paths[-1])\n",
    "    temp_path = os.path.join(temp_path, 'checkpoints/last.ckpt')\n",
    "    verbose_print(temp_path)\n",
    "    prune_cmd = f\"python prune-ckpt.py --ckpt {temp_path}\"\n",
    "    execute(prune_cmd)\n",
    "    verbose_print(f\"Model Pruning Complete!\")\n",
    "\n",
    "def train_button(prune_model_var):\n",
    "    # train the model\n",
    "    prompt = image_gen_config_df['prompt_string'].replace('_', ' ')\n",
    "    train_cmd = f\"python main.py --base {dataset_config_df['config_path']} -t --actual_resume {model_config_df['model_name']} \" \\\n",
    "                f\"--reg_data_root {image_gen_config_df['final_img_path']} -n {dataset_config_df['project_name']} \" \\\n",
    "                f\"--gpus {system_config_df['gpu_used_var']}, --data_root {dataset_config_df['dataset_path']} \" \\\n",
    "                f\"--max_training_steps {train_config_df['max_training_steps']} --class_word {prompt} --token {dataset_config_df['class_token']} \" \\\n",
    "                f\"--no-test --batch_size {train_config_df['batch_size']} --workers {train_config_df['cpu_workers']}\"\n",
    "\n",
    "    verbose_print(\"============================== TRAINING COMMAND TEST ==============================\")\n",
    "    verbose_print(train_cmd)\n",
    "    verbose_print(\"============================== --------------------- ==============================\")\n",
    "\n",
    "    if (\"regularizer_var\" in image_gen_config_df and image_gen_config_df[\"regularizer_var\"] == 1):\n",
    "        if 'config_path' in dataset_config_df and 'model_name' in model_config_df and \\\n",
    "                'final_img_path' in image_gen_config_df and 'project_name' in dataset_config_df and \\\n",
    "                'gpu_used_var' in system_config_df and 'dataset_path' in dataset_config_df and \\\n",
    "                'max_training_steps' in train_config_df and prompt:\n",
    "            for line in execute(train_cmd.split(\" \")):\n",
    "                verbose_print(line)\n",
    "    else:\n",
    "        verbose_print(\"Please make sure to SAVE your settings before trying to Generate and/or Train.\")\n",
    "\n",
    "    prune_model_var = gr.Button(value=\"Prune Model\", variant='secondary', visible=True)\n",
    "    return prune_model_var\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Model & Data Configuration\"):\n",
    "        config_save_var = gr.Button(value=\"Apply & Save Settings\", variant='primary')\n",
    "        gr.Markdown(\n",
    "        \"\"\"\n",
    "        ### Make sure a stable diffusion model with the (.ckpt) extension has been downloaded\n",
    "        ### Please move the downloaded model into \"this\" repository folder\n",
    "        \"\"\")\n",
    "\n",
    "        verbose_print(f\"ckpt_files {ckpt_files}\")\n",
    "\n",
    "        with gr.Row():\n",
    "            if \"model_name\" in model_config_df:\n",
    "                model_var = gr.inputs.Radio(ckpt_files, type=\"value\", default=str(model_config_df[\"model_name\"]), label='Select Model')\n",
    "            else:\n",
    "                model_var = gr.inputs.Radio(ckpt_files, type=\"value\", label='Select Model')\n",
    "\n",
    "        if \"project_name\" in dataset_config_df:\n",
    "            project_name = gr.Textbox(lines=1, interactive=True, label='Project Name', value=str(dataset_config_df[\"project_name\"]))\n",
    "        else:\n",
    "            project_name = gr.Textbox(lines=1, interactive=True, label='Project Name')\n",
    "        if \"class_token\" in dataset_config_df:\n",
    "            class_token = gr.Textbox(lines=1, interactive=True, label='Token (e.g. firstnamelastname)', value=str(dataset_config_df[\"class_token\"]))\n",
    "        else:\n",
    "            class_token = gr.Textbox(lines=1, interactive=True, label='Token (e.g. firstnamelastname)')\n",
    "        if \"config_path\" in dataset_config_df:\n",
    "            config_path = gr.Textbox(lines=1, interactive=True, label='Path to Model YAML Config', value=str(dataset_config_df[\"config_path\"]))\n",
    "        else:\n",
    "            config_path = gr.Textbox(lines=1, interactive=True, label='Path to Model YAML Config')\n",
    "        if \"dataset_path\" in dataset_config_df:\n",
    "            dataset_path = gr.Textbox(lines=1, interactive=True, label='Path to Class Target Dataset', value=str(dataset_config_df[\"dataset_path\"]))\n",
    "        else:\n",
    "            dataset_path = gr.Textbox(lines=1, interactive=True, label='Path to Class Target Dataset')\n",
    "        if \"reg_dataset_path\" in dataset_config_df:\n",
    "            reg_dataset_path = gr.Textbox(lines=1, interactive=True, label='Path to Regularization Dataset', value=str(dataset_config_df[\"reg_dataset_path\"]))\n",
    "        else:\n",
    "            reg_dataset_path = gr.Textbox(lines=1, interactive=True, label='Path to Regularization Dataset')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                if \"verbose\" in model_config_df:\n",
    "                    verbose = gr.Checkbox(interactive=True, label='Verbose Mode', value=bool(model_config_df[\"verbose\"]))\n",
    "                else:\n",
    "                    model_config_df[\"verbose\"] = False\n",
    "                    verbose = gr.Checkbox(interactive=True, label='Verbose Mode', value=False)\n",
    "            with gr.Column():\n",
    "                if not \"gpu_used_var\" in system_config_df:\n",
    "                    system_config_df[\"gpu_used_var\"] = [i for i in range(0, torch.cuda.device_count())][0] # EXPECT THIS TO CHANGE IN THE FUTURE\n",
    "                temp_text = [f\"gpu: {i}\" for i in range(0, torch.cuda.device_count())]\n",
    "                gpu_used_var = gr.inputs.Radio(temp_text, default=temp_text[(system_config_df[\"gpu_used_var\"])], label='Select GPU')\n",
    "\n",
    "    with gr.Tab(\"Image Regularization\"):\n",
    "        gr.Markdown(\n",
    "        \"\"\"\n",
    "        ### Please make sure that if you are using a custom regularization dataset, that the images are formatted 512x512\n",
    "        ### Here is an online formatter for cropping images if needed [https://www.birme.net/](https://www.birme.net/)\n",
    "        \"\"\")\n",
    "        regularizer_save_var = gr.Button(value=\"Apply & Save Settings\", variant='primary')\n",
    "        image_gen_output = None\n",
    "        with gr.Row():\n",
    "            reg_options = ['Custom (REG) Images (🔺 stylization, 🔻 robustness)', 'Auto (REG) Images (🔺 robustness,🔻 stylization)']\n",
    "            if \"regularizer_var\" in image_gen_config_df:\n",
    "                regularizer_var = gr.inputs.Radio(reg_options,\n",
    "                                type=\"value\", default=reg_options[(image_gen_config_df[\"regularizer_var\"])], label='Select Regularization Approach')\n",
    "            else:\n",
    "                regularizer_var = gr.inputs.Radio(reg_options,\n",
    "                                type=\"value\", label='Select Regularization Approach')\n",
    "            if not \"final_img_path\" in image_gen_config_df and not \"reg_dataset_path\" in dataset_config_df:\n",
    "                final_img_path = gr.Textbox(lines=1, interactive=True, label='Regularization Data Path')\n",
    "            elif \"reg_dataset_path\" in dataset_config_df:\n",
    "                final_img_path = gr.Textbox(lines=1, interactive=True, label='Regularization Data Path',\n",
    "                                            value=str(dataset_config_df[\"reg_dataset_path\"]))\n",
    "            elif \"final_img_path\" in image_gen_config_df:\n",
    "                final_img_path = gr.Textbox(lines=1, interactive=True, label='Regularization Data Path',\n",
    "                                            value=str(image_gen_config_df[\"final_img_path\"]))\n",
    "\n",
    "        if \"seed_var\" in image_gen_config_df:\n",
    "            seed_var = gr.Textbox(lines=1, interactive=True, label='Seed Number (int)', value=str(image_gen_config_df[\"seed_var\"]))\n",
    "        else:\n",
    "            seed_var = gr.Textbox(lines=1, interactive=True, label='Seed Number (int)', value=str(10))\n",
    "        if \"ddim_eta_var\" in image_gen_config_df:\n",
    "            ddim_eta_var = gr.Textbox(lines=1, interactive=True, label='DDIM eta (float)', value=str(image_gen_config_df[\"ddim_eta_var\"]))\n",
    "        else:\n",
    "            ddim_eta_var = gr.Textbox(lines=1, interactive=True, label='DDIM eta (float)', value=str(0.0))\n",
    "        if \"scale_var\" in image_gen_config_df:\n",
    "            scale_var = gr.Textbox(lines=1, interactive=True, label='Scale (float)', value=str(image_gen_config_df[\"scale_var\"]))\n",
    "        else:\n",
    "            scale_var = gr.Textbox(lines=1, interactive=True, label='Scale (float)', value=str(10.0))\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                if \"prompt_string\" in image_gen_config_df:\n",
    "                    prompt_string = gr.Textbox(lines=1, interactive=True, label='Regularization Prompt (e.g. Person)', value=str(image_gen_config_df[\"prompt_string\"]))\n",
    "                else:\n",
    "                    prompt_string = gr.Textbox(lines=1, interactive=True, label='Regularization Prompt (e.g. Person)')\n",
    "            with gr.Column():\n",
    "                if \"keep_jpgs\" in image_gen_config_df:\n",
    "                    keep_jpgs = gr.Checkbox(interactive=True, label='Keep JPGs', value=bool(image_gen_config_df[\"keep_jpgs\"]))\n",
    "                else:\n",
    "                    image_gen_config_df[\"keep_jpgs\"] = False\n",
    "                    keep_jpgs = gr.Checkbox(interactive=True, label='Keep JPGs', value=False)\n",
    "\n",
    "        if \"n_samples\" in image_gen_config_df:\n",
    "            n_samples = gr.Slider(minimum=0, maximum=200, step=1, label='Samples per Iteration (i.e. batch size)', value=int(image_gen_config_df[\"n_samples\"]))\n",
    "        else:\n",
    "            n_samples = gr.Slider(minimum=0, maximum=200, step=1, value=1, label='Samples per Iteration (i.e. batch size)')\n",
    "        if \"n_iter\" in image_gen_config_df:\n",
    "            n_iter = gr.Slider(minimum=0, maximum=1000, step=10, label='Number of Iterations', value=int(image_gen_config_df[\"n_iter\"]))\n",
    "        else:\n",
    "            n_iter = gr.Slider(minimum=0, maximum=1000, step=10, value=200, label='Number of Iterations')\n",
    "        if \"ddim_steps\" in image_gen_config_df:\n",
    "            ddim_steps = gr.Slider(minimum=0, maximum=250, step=5, label='Sampler Steps', value=int(image_gen_config_df[\"ddim_steps\"]))\n",
    "        else:\n",
    "            ddim_steps = gr.Slider(minimum=0, maximum=250, step=5, value=50, label='Sampler Steps')\n",
    "\n",
    "        with gr.Row():\n",
    "            generate_images_var = gr.Button(value=\"Generate\", variant='secondary')\n",
    "\n",
    "    with gr.Tab(\"Fine-Tuning Model\"):\n",
    "        fine_tine_save_var = gr.Button(value=\"Apply & Save Settings\", variant='primary')\n",
    "\n",
    "        if \"max_training_steps\" in train_config_df:\n",
    "            max_training_steps = gr.Slider(minimum=0, maximum=20000, step=20, label='Max Training Steps', value=int(train_config_df[\"max_training_steps\"]))\n",
    "        else:\n",
    "            max_training_steps = gr.Slider(minimum=0, maximum=20000, step=20, label='Max Training Steps', value=2000)\n",
    "        if \"batch_size\" in train_config_df:\n",
    "            batch_size = gr.Slider(minimum=1, maximum=64, step=1, label='Batch Size', value=int(train_config_df[\"batch_size\"]))\n",
    "        else:\n",
    "            batch_size = gr.Slider(minimum=1, maximum=64, step=1, label='Batch Size', value=1)\n",
    "        if \"cpu_workers\" in train_config_df:\n",
    "            cpu_workers = gr.Slider(minimum=1, maximum=mp.cpu_count(), step=1, label='Worker Threads', value=int(train_config_df[\"cpu_workers\"]))\n",
    "        else:\n",
    "            cpu_workers = gr.Slider(minimum=1, maximum=mp.cpu_count(), step=1, label='Worker Threads', value=int(mp.cpu_count()/2))\n",
    "\n",
    "        with gr.Row():\n",
    "            train_out_var = gr.Button(value=\"Generate\", variant='secondary')\n",
    "            prune_model_var = gr.Button(value=\"Prune Model\", variant='secondary', visible=False)\n",
    "\n",
    "    model_var.change(fn=model_choice, inputs=[model_var], outputs=[])\n",
    "    config_save_var.click(fn=model_config_save_button,\n",
    "                          inputs=[model_var,\n",
    "                                  gpu_used_var,\n",
    "                                  project_name,\n",
    "                                  class_token,\n",
    "                                  config_path,\n",
    "                                  dataset_path,\n",
    "                                  reg_dataset_path\n",
    "                                  ],\n",
    "                          outputs=[final_img_path]\n",
    "                          )\n",
    "    verbose.change(fn=verbose_checkbox, inputs=[], outputs=[])\n",
    "\n",
    "    regularizer_var.change(fn=change_regularizer_view, inputs=[regularizer_var], outputs=[])\n",
    "    regularizer_save_var.click(fn=image_gen_config_save_button, inputs=[final_img_path,\n",
    "                                                                        seed_var,\n",
    "                                                                        ddim_eta_var,\n",
    "                                                                        scale_var,\n",
    "                                                                        prompt_string,\n",
    "                                                                        n_samples,\n",
    "                                                                        n_iter,\n",
    "                                                                        ddim_steps,\n",
    "                                                                        keep_jpgs\n",
    "                                                                        ], outputs=[reg_dataset_path])\n",
    "\n",
    "    generate_images_var.click(fn=image_generation_button, inputs=[keep_jpgs], outputs=[], show_progress=True, scroll_to_output=True)\n",
    "\n",
    "    fine_tine_save_var.click(fn=train_save_button, inputs=[max_training_steps,\n",
    "                                                                        batch_size,\n",
    "                                                                        cpu_workers\n",
    "                                                                        ], outputs=[])\n",
    "    train_out_var.click(fn=train_button, inputs=[prune_model_var], outputs=[prune_model_var], show_progress=True, scroll_to_output=True)\n",
    "    prune_model_var.click(fn=prune_ckpt, inputs=[], outputs=[])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
